Homework 2
================
Jerry Chao
9/24/2020

## This is my solution to Homework 2

## Problem 0

I have created a GitHub repo as well as local R Project named
“p8105\_hw2\_jyc2171”, followed by one single .Rmd file named
“p8105\_hw2\_jyc2171.Rmd” that renders to GitHub repo. A subdirectory
was created to use the data files Mr. Trash Wheel (Problem 1), NYC
transit data (Problem 2), and FiveThiryEight (Problem 3) using relative
paths. This homework shall be submitted via courseworks as a URL to my
GitHub repo. Thanks.

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1 - Mr. Trash Wheel dataset. Read and clean dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data\! for 2018 and 2017.

``` r
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
    
precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)
  
left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trash Wheel trash
collector in Baltimore, MD. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, trash collected, weight and volume
of trash collected, and some specific kinds of trash. There are a total
of 344 rows in our final dataset and 14 columns. Additional data sheets
are provided for the other members of the family: Professor Trash Wheel
and Captain Trash Wheel. Other sheets include monthly precipitation data
from 2014 to 2019 and a homes powered note.

The Precip 2017 and Precip 2018 sheets contain information about monthly
precipitation (measured in inches) in 2017 and 2018. The Precip 2017
dataset contains 3 columns and 12 rows. The Precip 2018 dataset contains
3 columns and 12 rows. The datasets were joined together in one dataset
in the “precip\_df” with 3 columns and 24 rows.

The total precipitation in 2018 was 70.33 inches. The median number of
sports balls in a dumpster in 2017 was 8 balls.

For practice, as done in synchronous class session, re-running code with
most updated Mr. Trashwheel data.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

## Problem 2 - NYC Transit data\!

``` r
nyc_transit =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select(-division, -exit_only, -staffing, -staff_hours, -ada_notes, -free_crossover, -north_south_street,               -east_west_street, -corner, -entrance_latitude, -entrance_longitude, -station_location,                         -entrance_location) %>% 
  ## select(starts with("route"))
  relocate(entry) %>% 
  mutate(
    entry = recode(entry, "YES" = "1", "NO" = "0"), 
    vending = recode(vending, "YES" = "1", "NO" = "0"),     
    entrance_type = str_to_lower(entrance_type),
    ada = str_to_lower(ada)     
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The NYC Transit data set contains information about New York City MTA
subway stations. The variables include station names, what line, the
latitude and longitude of the station, which subway routes stop at the
station, whether or not there is entry to that station, the types of
entry, whether they are Americans with Diasabilities Act accessible,
and, finally, whether there are vending machines. For data cleaning, I
retained/selected a certain number of specified variables and dropped
the rest, converted the group variable names to snake case, and changed
the contents of character variables to logical variables, and changed to
lowercase letters. There are a total of 1868 rows and 19 columns. These
data seem to be tidy because they are in long format and list all of the
possible data points.  
There are a total of 356 distinct stations. There are \`\` stations that
are ADA compliant.
