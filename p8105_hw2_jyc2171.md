Homework 2
================
Jerry Chao Uni jyc2171
9/24/2020

## This is my solution to Homework 2

## Problem 0

I have created a GitHub repo as well as local R Project named
“p8105\_hw2\_jyc2171”, followed by one single .Rmd file named
“p8105\_hw2\_jyc2171.Rmd” that renders to GitHub repo. A subdirectory
was created to use the data files Mr. Trash Wheel (Problem 1), NYC
transit data (Problem 2), and FiveThiryEight (Problem 3) using relative
paths. This homework shall be submitted via courseworks as a URL to my
GitHub repo. Thanks.

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1 - Mr. Trash Wheel dataset. Read and clean dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  separate(date, c("year", "month", "day")) %>% 
  relocate(dumpster, year, month, day) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
    
precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
    ) %>% 
  mutate(
    month = as.double(month)
  )

precip_combined = 
  bind_rows(precip_2018, precip_2017) %>% 
  arrange(year)

left_join(precip_combined, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>% 
  relocate(year, month)
```

    ## # A tibble: 24 x 3
    ##     year month     total
    ##    <dbl> <chr>     <dbl>
    ##  1  2017 January    2.34
    ##  2  2017 February   1.46
    ##  3  2017 March      3.57
    ##  4  2017 April      3.99
    ##  5  2017 May        5.64
    ##  6  2017 June       1.4 
    ##  7  2017 July       7.09
    ##  8  2017 August     4.44
    ##  9  2017 September  1.95
    ## 10  2017 October    0   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trash Wheel trash
collector in Baltimore, MD. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, trash collected, weight and volume
of trash collected, and some specific kinds of trash. There are a total
of 344 rows in our final dataset and 14 columns. Additional data sheets
are provided for the other members of the family: Professor Trash Wheel
and Captain Trash Wheel. Other sheets include monthly precipitation data
from 2014 to 2019 and a homes powered note.

The Precip 2017 and Precip 2018 sheets contain information about monthly
precipitation (measured in inches) in 2017 and 2018. The Precip 2017
dataset contains 3 columns and 12 rows. The Precip 2018 dataset contains
3 columns and 12 rows. The datasets were joined together in one dataset
in the “precip\_df” with 3 columns and 24 rows.

The total precipitation in 2018 was 70.33 inches. The median number of
sports balls in a dumpster in 2017 was 8 balls.

For practice, as done in synchronous class session, re-running code with
most updated Mr. Trashwheel data.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

## Problem 2 - NYC Transit data\!

``` r
nyc_transit =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select(-division, -exit_only, -staffing, -staff_hours, -ada_notes, -free_crossover, -north_south_street,               -east_west_street, -corner, -entrance_latitude, -entrance_longitude, -station_location,                         -entrance_location) %>% 
  relocate(entry, ada) %>% 
  mutate(
    entry = recode(entry, "YES" = TRUE,  "NO" = FALSE),
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11),
    entrance_type = str_to_lower(entrance_type),
    ada = str_to_lower(ada),
    entry = str_to_lower(entry),
    vending = str_to_lower(vending)
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The NYC Transit data set contains information about New York City MTA
subway stations. The variables include station names, what line, the
latitude and longitude of the station, which subway routes stop at the
station, whether or not there is entry to that station, the types of
entry, whether they are Americans with Diasabilities Act accessible,
and, finally, whether there are vending machines. For data cleaning, I
retained/selected a certain number of specified variables and dropped
the rest, converted the group variable names to snake case, and changed
the contents of character variables to logical variables, and changed to
lowercase letters. There are a total of 1868 rows and 19 columns. These
data seem to be tidy because they are in long format and list all of the
possible data points.  
There are a total of 356 distinct stations. There are 0 stations that
are ADA compliant (Answer is 73 but I cannot get the R markdown file to
knit). The number of station entrance/exits without vending machines
that allow entrance is 0 (Answer is 69). Therefore, the proportion of
station entrance/exits without vending machines that allow entrance is:
69/1,868 = 3.7%.

There are 24 distinct train lines that exist (obtained by looking at
distinct number of rows in the route1 variable, which should have all
possible train lines listed).

``` r
transit_tidy =
  nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "train_name"
  )
```

The data has been reformatted to long, generating a new dataframe that
consists of 20548 rows and 10 columns.  
There are 56 distinct stations that serve the A train.

## Problem 3 - FiveThirtyEight data\!\!

First, the pols-months.csv data.

``` r
pols_months =
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, c("year", "month", "day")) %>%
  mutate(
    year = as.numeric(year),
    president = (prez_dem * 2) + prez_gop,
    president = recode(president, "2" = "dem", "1" = "gop"),
    month = recode(month, "01" = "january", "02" = "february", "03" = "march", "04" = "april", "05" =                              "may", "06" = "june", "07" = "july", "08" = "august", "09" = "september", "10" =                                "october", "11" = "november", "12" = "december") 
    ) %>% 
    select(-prez_gop, -prez_dem, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Next, the snp.csv data.

``` r
stock_df =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, c("month", "day", "year")) %>% 
  select(-day) %>%
  relocate(year) %>% 
  arrange(year) %>% 
  mutate(
    year = as.numeric(year),
    month = recode(month, "7" = "july", "6" = "june", "5" = "may", "4" = "april", "3" = "march", "2" =                             "february", "1" = "january", "12" = "december", "11" = "november", "10" = "october", "9" =                      "september", "8" = "august")
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Finally, the unemployment data.

``` r
unemploy_df =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  select(year, january = jan, february = feb, march = mar, april = apr, may, june = jun, july = jul, august =            aug, september = sep, october = oct, november = nov, december = dec) %>% 
  pivot_longer(
    january:december,
    names_to = "month",
    values_to = "unemployment"
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Joining the three datasets.

``` r
stock_pols =
  left_join(pols_months, stock_df)
```

    ## Joining, by = c("year", "month")

``` r
final_merge =
  left_join(stock_pols, unemploy_df)
```

    ## Joining, by = c("year", "month")

All three datasets have beencleaned and joined. The “pols-month” dataset
contains the number national politicians who are democratric or
republican at any time. The dataset contains 9 columns and 822 rows. The
cleaned dataset contains the following variables: year, month, number of
governers who are dems or republicans, number of senators who are dems
or republicans, number of representatives who are dems or republicans,
and a president variable with the political party. The years in the
dataset range from 1947 t 2015 The “snp” dataset contains the closing
value of Standard & Poor’s stock market index on a given month of a
year. The dataset contains 3 columns and 787 rows. The years in the
dataset range from 1950 to 2015. The “unemployment” dataset contains the
percentage of unemployment per month in the associated year. The datset
was converted to long format and consists of `n col(unemploy_df)`
columns and `n row(unempoly_df)` rows. The years in the dataset range
from 1948 to 2015.
